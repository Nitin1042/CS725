{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f98c8f9f-9dcc-4fc2-b2c0-a08806fe7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import get_window\n",
    "from scipy.fft import rfft, dct\n",
    "from scipy.signal import stft\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac182eb5-bc40-40c2-a795-8c199d6c31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Audio Files\n",
    "\n",
    "def load_wav_file(file_path):\n",
    "    sample_rate, audio_data = wavfile.read(file_path)\n",
    "    return sample_rate, audio_data\n",
    "\n",
    "def load_audio_files(directory):\n",
    "    features = []\n",
    "    track_names = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            if filename.endswith('.wav'):\n",
    "                try:\n",
    "                    sample_rate, audio_data = load_wav_file(file_path)\n",
    "                    if audio_data.ndim == 1:  # Check for mono audio\n",
    "                        features.append(audio_data)\n",
    "                        track_names.append(filename)\n",
    "                    else:\n",
    "                        print(f\"Skipping non-mono audio file: {file_path}\")\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error with {file_path}: {e}\")\n",
    "\n",
    "    # Convert features to a 2D array if possible\n",
    "    if features:\n",
    "        # Pad the features to have the same length\n",
    "        max_length = max(len(f) for f in features)\n",
    "        padded_features = np.array([np.pad(f, (0, max_length - len(f)), 'constant') for f in features])\n",
    "    else:\n",
    "        padded_features = np.empty((0,))  # Handle the case with no valid features\n",
    "\n",
    "    return padded_features, track_names\n",
    "\n",
    "# Step 2: Feature Extraction\n",
    "\n",
    "def compute_mfcc(audio_data, sample_rate, num_coefficients=13):\n",
    "    frame_size = 2048\n",
    "    hop_size = 512\n",
    "    num_frames = (len(audio_data) - frame_size) // hop_size + 1\n",
    "    hamming_window = get_window('hamming', frame_size)\n",
    "\n",
    "    mfccs = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        frame = audio_data[i * hop_size:i * hop_size + frame_size]\n",
    "        windowed_frame = frame * hamming_window\n",
    "        spectrum = np.abs(rfft(windowed_frame))**2\n",
    "        \n",
    "        mel_filters = np.zeros((num_coefficients, len(spectrum)))\n",
    "        mel_bins = np.linspace(0, len(spectrum) - 1, num_coefficients + 2).astype(int)\n",
    "\n",
    "        for j in range(num_coefficients):\n",
    "            mel_filters[j, mel_bins[j]:mel_bins[j + 1]] = 1\n",
    "        \n",
    "        mel_energy = np.dot(mel_filters, spectrum)\n",
    "        mel_energy = np.log(mel_energy + 1e-10)\n",
    "        mfcc = dct(mel_energy, type=2, norm='ortho')\n",
    "        mfccs.append(mfcc)\n",
    "    \n",
    "    #print(\"MFCCS DONE\")\n",
    "    \n",
    "    return np.mean(mfccs, axis=0)\n",
    "\n",
    "def compute_chroma_features(audio_data, sample_rate):\n",
    "    # Compute the short-time Fourier transform (STFT)\n",
    "    f, t, Zxx = stft(audio_data, fs=sample_rate, nperseg=2048, noverlap=512)\n",
    "    magnitude = np.abs(Zxx)\n",
    "    \n",
    "    # Chroma filter bank\n",
    "    num_chroma_bins = 12\n",
    "    chroma = np.zeros((num_chroma_bins, magnitude.shape[1]))\n",
    "    \n",
    "    # Map frequencies to chroma bins\n",
    "    for i in range(len(f)):\n",
    "        bin_freq = f[i]\n",
    "        if bin_freq > 0:  # Avoid log(0)\n",
    "            pitch_class = int(12 * np.log2(bin_freq / 440.0)) % 12\n",
    "            if 0 <= pitch_class < num_chroma_bins:\n",
    "                chroma[pitch_class] += magnitude[i, :]\n",
    "    \n",
    "    #print(\"Chroma DONE\")\n",
    "    \n",
    "    return np.mean(chroma, axis=1)\n",
    "\n",
    "def compute_spectral_contrast(audio_data):\n",
    "    spectrum = np.abs(rfft(audio_data))**2\n",
    "    # Use slicing that maintains the same length\n",
    "    peaks = np.where((spectrum[:-2] < spectrum[1:-1]) & (spectrum[1:-1] > spectrum[2:]))[0] + 1\n",
    "    valleys = np.where((spectrum[:-2] > spectrum[1:-1]) & (spectrum[1:-1] < spectrum[2:]))[0] + 1\n",
    "    \n",
    "    # Avoid empty arrays when calculating means\n",
    "    if peaks.size > 0 and valleys.size > 0:\n",
    "        contrast = np.mean(spectrum[peaks]) - np.mean(spectrum[valleys])\n",
    "    else:\n",
    "        contrast = 0  # Default value if no peaks or valleys found\n",
    "\n",
    "    #print(\"Contrast Done\")\n",
    "    \n",
    "    return contrast\n",
    "\n",
    "def compute_tempo(audio_data):\n",
    "    frame_size = 2048\n",
    "    hop_size = 512\n",
    "    num_frames = (len(audio_data) - frame_size) // hop_size + 1\n",
    "    energy = np.array([np.sum(audio_data[i * hop_size:i * hop_size + frame_size] ** 2) for i in range(num_frames)])\n",
    "\n",
    "    #print(\"Tempo DONE\")\n",
    "    \n",
    "    return np.mean(energy)\n",
    "\n",
    "def extract_features(audio_data, sample_rate):\n",
    "    mfccs = compute_mfcc(audio_data, sample_rate)\n",
    "    chroma = compute_chroma_features(audio_data, sample_rate)\n",
    "    spectral_contrast = compute_spectral_contrast(audio_data)\n",
    "    tempo = compute_tempo(audio_data)\n",
    "    \n",
    "    return np.concatenate([mfccs, chroma, [spectral_contrast], [tempo]])\n",
    "\n",
    "\n",
    "# Step 3: Similarity Checks\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "def manhattan_distance(a, b):\n",
    "    return np.sum(np.abs(a - b))\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 1.0\n",
    "        \n",
    "    cosine_similarity = dot_product / (norm_a * norm_b)\n",
    "    return 1 - cosine_similarity  # Convert similarity to distance\n",
    "\n",
    "def dtw(a, b):\n",
    "    # Initialize the cost matrix\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    cost = np.zeros((n + 1, m + 1))\n",
    "\n",
    "    # Initialize the cost matrix with infinity\n",
    "    cost[0, :] = np.inf\n",
    "    cost[:, 0] = np.inf\n",
    "    cost[0, 0] = 0\n",
    "\n",
    "    # Populate the cost matrix\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            # Calculate the cost\n",
    "            dist = abs(a[i - 1] - b[j - 1])\n",
    "            cost[i, j] = dist + min(cost[i - 1, j],    # Insertion\n",
    "                                    cost[i, j - 1],    # Deletion\n",
    "                                    cost[i - 1, j - 1] # Match\n",
    "                                   )\n",
    "\n",
    "    # Return the last element of the cost matrix, which contains the DTW distance\n",
    "    return cost[n, m]\n",
    "\n",
    "def compute_distances(input_features, features):\n",
    "    euclidean_distances = np.array([euclidean_distance(input_features, feature) for feature in features])\n",
    "    manhattan_distances = np.array([manhattan_distance(input_features, feature) for feature in features])\n",
    "    cosine_distances = np.array([cosine_distance(input_features, feature) for feature in features])\n",
    "    dtw_distances = np.array([dtw(input_features, feature) for feature in features])\n",
    "    \n",
    "    return euclidean_distances, manhattan_distances, cosine_distances, dtw_distances\n",
    "\n",
    "def whiten(features):\n",
    "    # Center the features by subtracting the mean\n",
    "    mean = np.mean(features, axis=0)\n",
    "    centered_features = features - mean\n",
    "    \n",
    "    # Calculate the covariance matrix\n",
    "    covariance_matrix = np.cov(centered_features, rowvar=False)\n",
    "    \n",
    "    # Add a small value to the diagonal to ensure numerical stability\n",
    "    epsilon = 1e-5\n",
    "    covariance_matrix += epsilon * np.eye(covariance_matrix.shape[0])\n",
    "    \n",
    "    # Use SVD to compute the whitening matrix\n",
    "    U, S, Vt = np.linalg.svd(covariance_matrix)\n",
    "    \n",
    "    # Create the whitening matrix\n",
    "    whitening_matrix = np.dot(U, np.diag(1.0 / np.sqrt(S + epsilon))).dot(U.T)\n",
    "    \n",
    "    # Apply the whitening transformation\n",
    "    whitened_features = np.dot(centered_features, whitening_matrix)\n",
    "    \n",
    "    return whitened_features\n",
    "\n",
    "# Step 4: Recommendation System\n",
    "\n",
    "def recommend_tracks_by_distance(input_features, features, track_names, N=5):\n",
    "    # First, whiten the features\n",
    "    all_features = np.vstack([input_features, features])\n",
    "    whitened_features = whiten(all_features)\n",
    "\n",
    "    # Extract the whitened input features and features\n",
    "    whitened_input_features = whitened_features[0]\n",
    "    whitened_features = whitened_features[1:]\n",
    "\n",
    "    #Compute the distances\n",
    "    #euclidean_distances, manhattan_distances, cosine_distances, dtw_distances = compute_distances(input_features, features)\n",
    "    euclidean_distances, manhattan_distances, cosine_distances, dtw_distances = compute_distances(whitened_input_features, whitened_features)\n",
    "    \n",
    "    # Get the indices of the N closest tracks for each distance metric\n",
    "    closest_euclidean_indices = np.argsort(euclidean_distances)[:N]\n",
    "    closest_manhattan_indices = np.argsort(manhattan_distances)[:N]\n",
    "    closest_cosine_indices = np.argsort(cosine_distances)[:N]\n",
    "    closest_dtw_indices = np.argsort(dtw_distances)[:N]\n",
    "    \n",
    "    recommended_euclidean = [track_names[i] for i in closest_euclidean_indices]\n",
    "    recommended_manhattan = [track_names[i] for i in closest_manhattan_indices]\n",
    "    recommended_cosine = [track_names[i] for i in closest_cosine_indices]\n",
    "    recommended_dtw = [track_names[i] for i in closest_dtw_indices]\n",
    "\n",
    "    return recommended_euclidean, recommended_manhattan, recommended_cosine, recommended_dtw\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1146eeda-2747-4f71-b76f-a9a7fa99f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_features_to_csv(features, track_names, file_name='audio_features.csv'):\n",
    "    df = pd.DataFrame(features)\n",
    "    df['track_name'] = track_names\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "def load_features_from_csv(file_name='audio_features.csv'):\n",
    "    df = pd.read_csv(file_name)\n",
    "    features = df.iloc[:, :-1].values  # All columns except the last one\n",
    "    track_names = df['track_name'].tolist()  # Last column as track names\n",
    "    return features, track_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51c3bdc3-cf85-47e2-9d51-91e45ac2dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Main Function for Recommendation Based on Input Track\n",
    "\n",
    "def recommend_based_on_input(input_file, audio_directory):\n",
    "    # Load input audio file\n",
    "    sample_rate, input_audio_data = load_wav_file(input_file)\n",
    "    if input_audio_data is None:\n",
    "        return  # Exit if loading failed\n",
    "    \n",
    "    # Extract features for the input audio\n",
    "    input_features = extract_features(input_audio_data, sample_rate)\n",
    "    \n",
    "    # Load features from CSV if available, otherwise extract and save\n",
    "    file_name = \"C:/Users/nitin/OneDrive/Desktop/UNI/IITB/CS725-FML/Project/audio_features.csv\"\n",
    "\n",
    "    print(\"Input Data Done\")\n",
    "\n",
    "    count=0\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        features, track_names = load_features_from_csv(file_name)\n",
    "    else:\n",
    "        audio_data_list, track_names = load_audio_files(audio_directory)\n",
    "\n",
    "        # Initialize an empty list to hold the extracted features\n",
    "        features_list = []\n",
    "        for audio_data in audio_data_list:\n",
    "            if audio_data is not None:\n",
    "                extracted_features = extract_features(audio_data, sample_rate)\n",
    "                features_list.append(extracted_features)\n",
    "                count = count + 1\n",
    "                if((count%10) == 0):\n",
    "                    print(f\"File Number {count} done....\")\n",
    "        \n",
    "        features = np.array(features_list)        \n",
    "        save_features_to_csv(features, track_names, file_name)\n",
    "\n",
    "    print(\"Feature Extraction Done\")\n",
    "    \n",
    "    recommended_euclidean, recommended_manhattan, recommended_cosine, recommended_dtw = recommend_tracks_by_distance(input_features, features, track_names, N=5)\n",
    "    \n",
    "    return recommended_euclidean, recommended_manhattan, recommended_cosine, recommended_dtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c31f405-d627-4b81-bf7f-d00f1ce797f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Done\n",
      "Feature Extraction Done\n",
      "Recommended Tracks (Euclidean): ['hiphop.00067.wav', 'pop.00001.wav', 'jazz.00017.wav', 'classical.00058.wav', 'reggae.00032.wav']\n",
      "Recommended Tracks (Manhattan): ['hiphop.00067.wav', 'classical.00058.wav', 'jazz.00017.wav', 'reggae.00032.wav', 'pop.00001.wav']\n",
      "Recommended Tracks (Cosine): ['pop.00001.wav', 'pop.00074.wav', 'pop.00059.wav', 'hiphop.00003.wav', 'pop.00088.wav']\n",
      "Recommended Tracks (DTW): ['hiphop.00067.wav', 'classical.00058.wav', 'jazz.00017.wav', 'reggae.00032.wav', 'pop.00001.wav']\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_audio_file = \"C:/Users/nitin/OneDrive/Desktop/UNI/IITB/CS725-FML/Project/Data/genres_original/pop/pop.00001.wav\"\n",
    "    audio_directory = \"C:/Users/nitin/OneDrive/Desktop/UNI/IITB/CS725-FML/Project/Data/genres_original\"\n",
    "    recommendations_euclidean, recommendations_manhattan, recommendations_cosine, recommendations_dtw = recommend_based_on_input(input_audio_file, audio_directory)\n",
    "    print(\"Recommended Tracks (Euclidean):\", recommendations_euclidean)\n",
    "    print(\"Recommended Tracks (Manhattan):\", recommendations_manhattan)\n",
    "    print(\"Recommended Tracks (Cosine):\", recommendations_cosine)\n",
    "    print(\"Recommended Tracks (DTW):\", recommendations_dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8d865-0ac9-4499-b777-7788e8191aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
